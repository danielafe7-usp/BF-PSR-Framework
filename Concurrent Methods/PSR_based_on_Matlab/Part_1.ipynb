{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the re-implementation of the original code provided by the authors in Matlab.\n",
    "## In our proposal (BF-PSR), this method is simplified for a better understanding. Such por example: not use of\n",
    "## matrixes or extra software for the processing and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions : First compile all the cells of this jupyter notebook (Part_1) and them compilie all\n",
    "# the cells of jupyter notebook (Part_2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the training conversations and its labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "Training data loaded ... Number of conversations:  66927\n",
      "Groomers Train:  2016  Non-groomers Train:  64911\n",
      "Conversation 1:  Hola. hi. whats up?   ...\n",
      "Conversation 1 label:  0\n",
      "**************************************************\n",
      "\u001b[96m\n",
      "Testing data loaded ... Number of conversations:  155128\n",
      "Groomers Test:  3737  Non-groomers Test:  151391\n",
      "Conversation 1:  bugmail: [Bug 6978]   ...\n",
      "Conversation 1 label:  0\n"
     ]
    }
   ],
   "source": [
    "# Loading training data \n",
    "# Atributes : Conversation - Time start - Number of participants - Label (groomer/non-groomer)\n",
    "PATH =  \"../../Data/train.csv\"\n",
    "df  = pd.read_csv(PATH,encoding='utf-8',header=None)\n",
    "Xss_train,Xss_train_time,Ys_train = df[0],_,df[2]\n",
    "posis_train = np.argwhere(Ys_train==1)\n",
    "negis_train = np.argwhere(Ys_train==0)\n",
    "print('\\033[91m')\n",
    "print(\"Training data loaded ... Number of conversations: \",len(Xss_train))\n",
    "print(\"Groomers Train: \",len(posis_train),\" Non-groomers Train: \", len(negis_train))\n",
    "print(\"Conversation 1: \",Xss_train[0][:20],\" ...\")\n",
    "print(\"Conversation 1 label: \",Ys_train[0])\n",
    "print(\"*\"*50)\n",
    "print('\\033[96m')\n",
    "# Loading testing data \n",
    "# Atributes : Conversation - Time start - Number of participants - Label (groomer/non-groomer)\n",
    "PATH =  \"../../Data/test.csv\"\n",
    "df  = pd.read_csv(PATH,encoding='utf-8',header=None)\n",
    "Xss_test,Xss_test_time,Ys_test = df[0],_,df[2]\n",
    "posis_test = np.argwhere(Ys_test==1)\n",
    "negis_test = np.argwhere(Ys_test==0)\n",
    "print(\"Testing data loaded ... Number of conversations: \",len(Xss_test))\n",
    "print(\"Groomers Test: \",len(posis_test),\" Non-groomers Test: \", len(negis_test))\n",
    "print(\"Conversation 1: \",Xss_test[0][:20],\" ...\")\n",
    "print(\"Conversation 1 label: \",Ys_test[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacinf empty conversations with \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predadors Train:  2016  No Predadors Train:  64911\n",
      "Predadors Test:  3737  No Predadors Test:  151391\n"
     ]
    }
   ],
   "source": [
    "posis_train = np.argwhere(Ys_train==1)\n",
    "negis_train = np.argwhere(Ys_train==0)\n",
    "print(\"Predadors Train: \",len(posis_train),\" No Predadors Train: \", len(negis_train))\n",
    "posis_test = np.argwhere(Ys_test==1)\n",
    "negis_test = np.argwhere(Ys_test==0)\n",
    "print(\"Predadors Test: \",len(posis_test),\" No Predadors Test: \", len(negis_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning folders were we will save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in Directory:  0\n",
      "Number of files in Directory:  0\n"
     ]
    }
   ],
   "source": [
    "directory = glob.glob('NotFilterNgrmas/*')\n",
    "for f in directory:\n",
    "    os.remove(f)\n",
    "\n",
    "directory = glob.glob('TestDocumetnsNotProcess_alldata/*')\n",
    "for f in directory:\n",
    "    os.remove(f)\n",
    "    \n",
    "# Checkin that the folders are actually empty\n",
    "directory_name = \"NotFilterNgrmas/\"\n",
    "path, dirs, files = next(os.walk(directory_name))\n",
    "file_count = len(files)\n",
    "print(\"Number of files in Directory: \",file_count)\n",
    "\n",
    "#----\n",
    "\n",
    "directory_name = \"TestDocumetnsNotProcess_alldata/\"\n",
    "path, dirs, files = next(os.walk(directory_name))\n",
    "file_count = len(files)\n",
    "print(\"Number of files in Directory: \",file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start processing the covesrsations into n-grmas = 3, them we save them into the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Train Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_names = []\n",
    "posi_train = 0\n",
    "\n",
    "kval = 3 # Number of char grams\n",
    "# process positive documents\n",
    "for i in range (0,len(posis_train)):\n",
    "    idx = posis_train[i][0]\n",
    "    cad = Xss_train[idx].replace('\"','') \n",
    "    cad = cad.replace('.',' ') \n",
    "    cad = cad.replace(\"''\",' ')\n",
    "    \n",
    "    # get character ngrams        \n",
    "    # Extract n-grams at the character level\n",
    "    cad = cad.replace(' ','&')\n",
    "    ncad = ''\n",
    "    ii = 0\n",
    "    ij = kval\n",
    "    tflag = 1\n",
    "    while tflag:\n",
    "        if ij+1 <= len(cad):\n",
    "            ncad += ' ' +  cad[ii:ij]  + ' '\n",
    "            ii = ii + 1\n",
    "            ij = ij + 1\n",
    "        else:\n",
    "            tflag = 0\n",
    "    cad = ncad\n",
    "    #print(i)\n",
    "    valtr='trrainninng' \n",
    "    posi_train += 1\n",
    "        \n",
    "    name = \"NotFilterNgrmas/\" + str(posis_train[i][0]+1) + '_posi_' + valtr + '.txt'\n",
    "    all_files_names.append(name)\n",
    "    #print(name)\n",
    "    file = open(name,\"w+\") \n",
    "    file.write(cad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Train Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process negative documents\n",
    "nega_train = 0\n",
    "for i in range (0,len(negis_train)):\n",
    "    idx = negis_train[i][0]\n",
    "    cad = Xss_train[idx].replace('\"','') \n",
    "    cad = cad.replace('.',' ') \n",
    "    cad = cad.replace(\"''\",' ')\n",
    "    \n",
    "    # get character ngrams        \n",
    "    # Extract n-grams at the character level\n",
    "    #'''\n",
    "    cad = cad.replace(' ','&')\n",
    "    ncad = ''\n",
    "    ii = 0\n",
    "    ij = kval\n",
    "    tflag = 1\n",
    "    while tflag:\n",
    "        if ij+1 <= len(cad):\n",
    "            ncad += ' ' +  cad[ii:ij]  + ' '\n",
    "            ii = ii + 1\n",
    "            ij = ij + 1\n",
    "        else:\n",
    "            tflag = 0\n",
    "    cad = ncad\n",
    "\n",
    "    valtr='trrainninng' #teestiinng\n",
    "    nega_train += 1\n",
    "        \n",
    "    name = \"NotFilterNgrmas/\" + str(negis_train[i][0]+1) + '_nega_' + valtr + '.txt'\n",
    "    all_files_names.append(name)\n",
    "    #print(name)\n",
    "    file = open(name,\"w+\") \n",
    "    file.write(cad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bugmail: [Bug 6978] New: Mark eof-terminated script elements as malformed &lt;http://lists.w3.org/Archives/Public/public-html-bugzilla/2009May/0049.html&gt; Henri, can I ask you a Firefox build question (Windows)? 60659cfda992013e610f285c46692d28: sure, but I probably don't know the answer It appears the build runs through, it creates a firefox.exe in dist/bin when I start it, I get my standard install of FF (3.0.10) instead... Same if I make a package, unzip it, and start from there... 60659cfda992013e610f285c46692d28: do you already have the usual Firefox open? Likely So do I need to close all instances? ...other... 60659cfda992013e610f285c46692d28: at least with the Linux version, you need to (unless you run a different profile, which may be advisable anyway) Good point. Will be gone for a moment due to Chatzilla. Henri, that was the problem. ok. good that I can guess some windows things from linux behavior ah yeah, Firefox is annoying with that 60659cfda992013e610f285c46692d28, I was merely citing it because your message made it seem as if you thought there was WG agreement And I thought there was some treshold criteria for the tracker, but maybe things changed We don't need WG agreement to add something to the tracker. That's not what I'm saying In particular, if the author has an outstanding action (ACTION-123) to reply, due 8 days ago. Ian? Yes. Since when can non-telcon participants be assigned action items? What does this have to do with the telco? http://www.w3.org/html/wg/tracker/actions/123 Title: ACTION-123 - HTML Weekly Tracker (at www.w3.org) Let me state it differently, did he agree to taking that action item? It's against W3C protocol to assign action items to people who did not agree to taking them. I don't know, nor do I think he needs to. Based on experience with the W3C I'd say he has to agree But it is ok to add non-chartered stuff to a spec, and then not to reply when asked for th reasons? my 'agreement' to the tracker item assigned to me was that I thought it was against protocol to refuse when Zakim picked me as &quot;victim&quot; Ignoring process for a moment (it wasn't me who added the action...)... But if the WG asks the editor why he did something, I think it deserves an answer. You raised the issue two weeks ago. Things take a bit of time If Ian has the time to add these four chapters (vcard, icalendar, bibtext, atom), he probably also has time to explain why. If you catch him on IRC you can probably ask if he can prioritize it somewhat if a timely response is important to you I think the fact that there's an overdue action on him should be sufficient information that the WG wants feedback. Seems to me that it followed from the microdata use cases / requirements discussion 60659cfda992013e610f285c46692d28, I doubt he even knows an action item is assigned to him so he's both not attending telcos *and* not reading the minutes? 60659cfda992013e610f285c46692d28: FWIW I think the answer to the question is &quot;because it allows the use cases of rich drag and drop / clipboard items&quot; to be fulfilled Although obviously that is not an offical answer 60659cfda992013e610f285c46692d28, that seems like quite a leap from not knowing he has an action item (In my experience Ian always does action items on time.) 60659cfda992013e610f285c46692d28: And whilst I think it makes sense to consider taking the specific mocrodata bits out of HTML 5, keeping the D&amp;D stuff would make the specs codependant on each other. So I'm not sure you'd gain much *microdata (amongst other errors) gives up on finding rules on action items \n"
     ]
    }
   ],
   "source": [
    "for i in range (0,1):\n",
    "    idx = negis_test[i][0]\n",
    "    valtr='teestiinng' \n",
    "    \n",
    "    cad = Xss_test[idx].replace('\"','') \n",
    "    print(cad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Test Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_names = []\n",
    "all_files_test = []\n",
    "posi_test = 0\n",
    "kval = 3 # Number of char grams\n",
    "# process positive documents\n",
    "for i in range (0,len(posis_test)):\n",
    "    idx = posis_test[i][0]\n",
    "    valtr='teestiinng' \n",
    "    \n",
    "    cad = Xss_test[idx].replace('\"','') \n",
    "    cad = cad.replace('.',' ') \n",
    "    cad = cad.replace(\"''\",' ')\n",
    "    \n",
    "    # Saving the non-process documents\n",
    "    name = \"TestDocumetnsNotProcess_alldata/\" + str(posis_test[i][0]+1) + '_posi_' + valtr + '.txt'\n",
    "    all_files_test.append(name)\n",
    "    file_test = open(name,\"w+\") \n",
    "    file_test.write(cad)\n",
    "    #    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # get character ngrams        \n",
    "    # Extract n-grams at the character level\n",
    "    cad = cad.replace(' ','&')\n",
    "    ncad = ''\n",
    "    ii = 0\n",
    "    ij = kval\n",
    "    tflag = 1\n",
    "    while tflag:\n",
    "        if ij+1 <= len(cad):\n",
    "            ncad += ' ' +  cad[ii:ij]  + ' '\n",
    "            ii = ii + 1\n",
    "            ij = ij + 1\n",
    "        else:\n",
    "            tflag = 0\n",
    "    cad = ncad\n",
    "    #print(i)\n",
    "    \n",
    "    posi_test += 1\n",
    "        \n",
    "    name = \"NotFilterNgrmas/\" + str(posis_test[i][0]+1) + '_posi_' + valtr + '.txt'\n",
    "    all_files_names.append(name)\n",
    "    #print(name)\n",
    "    file = open(name,\"w+\") \n",
    "    file.write(cad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Test Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process negative documents\n",
    "nega_test = 0\n",
    "for i in range (0,len(negis_test)):\n",
    "    idx = negis_test[i][0]\n",
    "    valtr='teestiinng'\n",
    "    \n",
    "    cad = Xss_test[idx].replace('\"','') \n",
    "    cad = cad.replace('.',' ') \n",
    "    cad = cad.replace(\"''\",' ')\n",
    "    \n",
    "    # Saving the non-process documents\n",
    "    name = \"TestDocumetnsNotProcess_alldata/\" + str(negis_test[i][0]+1) + '_nega_' + valtr + '.txt'\n",
    "    all_files_test.append(name)\n",
    "    file_test = open(name,\"w+\") \n",
    "    file_test.write(cad)\n",
    "    #\n",
    "    \n",
    "    # get character ngrams        \n",
    "    # Extract n-grams at the character level\n",
    "    #'''\n",
    "    cad = cad.replace(' ','&')\n",
    "    ncad = ''\n",
    "    ii = 0\n",
    "    ij = kval\n",
    "    tflag = 1\n",
    "    while tflag:\n",
    "        if ij+1 <= len(cad):\n",
    "            ncad += ' ' +  cad[ii:ij]  + ' '\n",
    "            ii = ii + 1\n",
    "            ij = ij + 1\n",
    "        else:\n",
    "            tflag = 0\n",
    "    cad = ncad\n",
    "\n",
    "    \n",
    "    nega_test += 1\n",
    "        \n",
    "    name = \"NotFilterNgrmas/\" + str(negis_test[i][0]+1) + '_nega_' + valtr + '.txt'\n",
    "    all_files_names.append(name)\n",
    "    #print(name)\n",
    "    file = open(name,\"w+\") \n",
    "    file.write(cad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predadors:  2016  No Predadors:  64911\n",
      "Predadors:  3737  No Predadors:  151391\n"
     ]
    }
   ],
   "source": [
    "print(\"Predadors: \",(posi_train),\" No Predadors: \", (nega_train))\n",
    "print(\"Predadors: \",(posi_test),\" No Predadors: \", (nega_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in Directory:  222055\n"
     ]
    }
   ],
   "source": [
    "directory_name = \"NotFilterNgrmas/\"\n",
    "path, dirs, files = next(os.walk(directory_name))\n",
    "file_count = len(files)\n",
    "print(\"Number of files in Directory: \",file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222055\n"
     ]
    }
   ],
   "source": [
    "# Tittles are the saved documents in ordered form\n",
    "sort_files = sorted(files)\n",
    "print(len(sort_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in Directory:  155128\n"
     ]
    }
   ],
   "source": [
    "directory_name = \"TestDocumetnsNotProcess_alldata/\"\n",
    "path, dirs, files = next(os.walk(directory_name))\n",
    "file_count = len(files)\n",
    "print(\"Number of files in Directory: \",file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155128\n"
     ]
    }
   ],
   "source": [
    "# Tittles are the saved documents in ordered form\n",
    "sort_files = sorted(files)\n",
    "print(len(sort_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
